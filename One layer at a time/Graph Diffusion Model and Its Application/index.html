
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../..">
      
      
        <link rel="next" href="../../blog/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.11">
    
    
      
        <title>Graph Diffusion Model and Its Application - Stochastic Tangents</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/theme.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-introduction" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://lakhabishal.com/" title="Stochastic Tangents" class="md-header__button md-logo" aria-label="Stochastic Tangents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Stochastic Tangents
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Graph Diffusion Model and Its Application
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 2c-1.82 0-3.53.5-5 1.35C8 5.08 10 8.3 10 12s-2 6.92-5 8.65C6.47 21.5 8.18 22 10 22a10 10 0 0 0 10-10A10 10 0 0 0 10 2"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="white" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://lakhabishal.com/" title="Stochastic Tangents" class="md-nav__button md-logo" aria-label="Stochastic Tangents" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8z"/></svg>

    </a>
    Stochastic Tangents
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    One layer at a time
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            One layer at a time
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Graph Diffusion Model and Its Application
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Graph Diffusion Model and Its Application
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-forward-process" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Forward Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 Forward Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-1-training-a-ddpm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm 1: Training a DDPM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-reverse-process" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Reverse Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.2 Reverse Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-2-inference-on-a-ddpm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm 2: Inference on a DDPM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-training-objective" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Training Objective
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-guided-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 Guided Diffusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-graph-diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      2. Graph Diffusion Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Graph Diffusion Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-forward-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Forward Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-reverse-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Reverse Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-latent-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Latent Diffusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-applications" class="md-nav__link">
    <span class="md-ellipsis">
      3 Applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-molecule-and-protein-design" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Molecule and Protein Design
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-materials-design" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Materials Design
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-combinatorial-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Combinatorial Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-xai" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 xAI
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../blog/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1 Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-forward-process" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 Forward Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.1 Forward Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-1-training-a-ddpm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm 1: Training a DDPM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-reverse-process" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 Reverse Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1.2 Reverse Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algorithm-2-inference-on-a-ddpm" class="md-nav__link">
    <span class="md-ellipsis">
      Algorithm 2: Inference on a DDPM
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-training-objective" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 Training Objective
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-guided-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      1.4 Guided Diffusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-graph-diffusion-models" class="md-nav__link">
    <span class="md-ellipsis">
      2. Graph Diffusion Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Graph Diffusion Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21-forward-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 Forward Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22-reverse-process" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 Reverse Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#23-latent-diffusion" class="md-nav__link">
    <span class="md-ellipsis">
      2.3 Latent Diffusion
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-applications" class="md-nav__link">
    <span class="md-ellipsis">
      3 Applications
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3 Applications">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-molecule-and-protein-design" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Molecule and Protein Design
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-materials-design" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Materials Design
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-combinatorial-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Combinatorial Optimization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-xai" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 xAI
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Graph Diffusion Model and Its Application</h1>

<h2 id="1-introduction">1 Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">&para;</a></h2>
<p>The phenomenal performance of AI systems for image and video generation such as DALLE <sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>, Stable Diffusion <sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>, and Sora <sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup> has captured the imagination of people and triggered the interest of many <sup id="fnref:4"><a class="footnote-ref" href="#fn:4">4</a></sup> <sup id="fnref:5"><a class="footnote-ref" href="#fn:5">5</a></sup> <sup id="fnref:6"><a class="footnote-ref" href="#fn:6">6</a></sup> . Underlying these AI systems is a deep learning algorithm called diffusion models or denoising diffusion probabilistic models (DDPM). The diffusion model, first proposed by Sohl-Dickstein et al. <sup id="fnref:7"><a class="footnote-ref" href="#fn:7">7</a></sup>, and later improved by Ho et al. <sup id="fnref:8"><a class="footnote-ref" href="#fn:8">8</a></sup>, enabling practical use cases, is a physics-inspired generative model. In physics, diffusion refers to the process by which particles move from regions of higher concentration to regions of lower concentration to reach an equilibrium, mathematically captured by Fick’s laws <sup id="fnref:9"><a class="footnote-ref" href="#fn:9">9</a></sup>. These laws describe the rate of diffusion by taking into account the concentration gradient between two points <sup id="fnref:10"><a class="footnote-ref" href="#fn:10">10</a></sup>. High-dimensional data also behaves similarly to the randomly moving particles as they seek an optimal distribution or representation, making diffusion suitable for generative tasks <sup id="fnref2:10"><a class="footnote-ref" href="#fn:10">10</a></sup> .</p>
<p>The diffusion model involves two main processes: the forward process (diffusion) and the reverse process (denoising), as illustrated in Fig. 1. The forward process requires gradually degrading the data, such as an image, through a multi-step noise application that converts it into a sample from a Gaussian distribution, discussed in detail in Section 1.1. Conversely, the reverse process, detailed in Section 1.2, involves training a deep neural network to reverse the noising steps, enabling the generation of new data from Gaussian-distributed samples <sup id="fnref:11"><a class="footnote-ref" href="#fn:11">11</a></sup>. Unlike other generative models like Generative Adversarial Networks (GAN) <sup id="fnref:12"><a class="footnote-ref" href="#fn:12">12</a></sup>, diffusion models are easy to train and can scale well on parallel hardware, making them quite suitable for large-scale datasets <sup id="fnref2:11"><a class="footnote-ref" href="#fn:11">11</a></sup>. They also avoid the problem of instability during training and generate better results in comparison to those algorithms, leading to their increased adoption in research and applications <sup id="fnref:13"><a class="footnote-ref" href="#fn:13">13</a></sup>.</p>
<h3 id="11-forward-process">1.1 Forward Process<a class="headerlink" href="#11-forward-process" title="Permanent link">&para;</a></h3>
<p>The forward process incrementally introduces noise into the data, transforming a clean data point <span class="arithmatex">\(x_0\)</span> into a series of increasingly noisy latent variables <span class="arithmatex">\(x_1, x_2, \ldots, x_T\)</span> through a Markov chain defined as:</p>
<div class="arithmatex">\[
q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t I)
\]</div>
<p>Here, <span class="arithmatex">\(\beta_t\)</span> modulates the noise level, and <span class="arithmatex">\(\mathcal{N}\)</span> denotes a Gaussian distribution. The entirety of the forward process can be expressed as:</p>
<div class="arithmatex">\[
q(x_{1:T}|x_0) = \prod_{t=1}^T q(x_t|x_{t-1})
\]</div>
<p>A notable aspect of this process is the direct sampling of <span class="arithmatex">\(x_t\)</span> at any noise level using:</p>
<div class="arithmatex">\[
q(x_t|x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t}x_0, (1 - \bar{\alpha}_t)I)
\]</div>
<p>where:</p>
<div class="arithmatex">\[
\bar{\alpha}_t = \prod_{s=1}^t (1 - \beta_s)
\]</div>
<hr />
<h4 id="algorithm-1-training-a-ddpm">Algorithm 1: Training a DDPM <sup id="fnref:15"><a class="footnote-ref" href="#fn:15">15</a></sup><a class="headerlink" href="#algorithm-1-training-a-ddpm" title="Permanent link">&para;</a></h4>
<ol>
<li>For every image <span class="arithmatex">\(x_0\)</span> in your training dataset:</li>
<li><strong>Repeat</strong>:</li>
<li>Pick a random time step <span class="arithmatex">\(t \sim \text{Uniform}[1, T]\)</span>.</li>
<li>
<p>Draw a sample <span class="arithmatex">\(x_t \sim \mathcal{N}(x_t|\sqrt{\alpha_t}x_0, (1-\alpha_t)I)\)</span>, i.e.,</p>
<p>$$
 x_t = \alpha_t x_0 + \sqrt{1-\alpha_t}z, \, z \sim \mathcal{N}(0, I)
 $$</p>
</li>
<li>
<p>Take a gradient descent step on:
     $$
     \nabla_\phi || \hat{x}_\phi(x_t) - x_0 ||^2
     $$</p>
</li>
<li><strong>Until convergence</strong></li>
</ol>
<p>You can do this in batches, just like how you train any other neural network. Note that, here, you are training one denoising network <span class="arithmatex">\(\hat{x}_\phi\)</span> for all noisy conditions.</p>
<hr />
<h3 id="12-reverse-process">1.2 Reverse Process<a class="headerlink" href="#12-reverse-process" title="Permanent link">&para;</a></h3>
<p>The goal of the reverse process of the DDPM is to reconstruct the clean data by denoising, predicting <span class="arithmatex">\(x_{t-1}\)</span> from <span class="arithmatex">\(x_t\)</span> at each step using the equation:</p>
<div class="arithmatex">\[
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
\]</div>
<p>where <span class="arithmatex">\(\mu_\theta(x_t, t)\)</span> and  <span class="arithmatex">\(\Sigma_\theta(x_t, t)\)</span> are functions modeled by a neural network <span class="arithmatex">\(\theta\)</span>, determining the mean and covariance of the Gaussian distribution at each reverse step. The entire reverse process can be described as:</p>
<div class="arithmatex">\[
p_\theta(x_{0:T}) = p(x_T) \prod_{t=T}^1 p_\theta(x_{t-1}|x_t)
\]</div>
<p>This process begins with the assumption that the final noisy data point, <span class="arithmatex">\(x_T\)</span>, follows a Gaussian distribution, typically centered around zero with identity covariance. The subsequent denoising steps iteratively estimate the less noisy preceding states until the original data point <span class="arithmatex">\(x_0\)</span> is recovered.</p>
<hr />
<h5 id="algorithm-2-inference-on-a-ddpm">Algorithm 2: Inference on a DDPM <sup id="fnref2:15"><a class="footnote-ref" href="#fn:15">15</a></sup><a class="headerlink" href="#algorithm-2-inference-on-a-ddpm" title="Permanent link">&para;</a></h5>
<ol>
<li>You give a white noise vector <span class="arithmatex">\(x_T \sim \mathcal{N}(0, I)\)</span>.</li>
<li><strong>For</strong> <span class="arithmatex">\(t = T, T-1, \ldots, 1\)</span> <strong>do</strong>:</li>
<li>Calculate <span class="arithmatex">\(\hat{x}_\theta(x_t)\)</span> using our trained denoiser.</li>
<li>
<p>Update according to:</p>
<p>$$
  x_{t-1} = \frac{(1-\alpha_{t-1})\sqrt{\alpha_t}}{1-\alpha_t} x_t + \frac{(1-\alpha_t)\sqrt{\alpha_{t-1}}}{1-\alpha_t} \hat{x}_\theta(x_t) + \sigma_q(t)z, \, z \sim \mathcal{N}(0, I)
  $$</p>
</li>
<li>
<p><strong>End For</strong></p>
</li>
</ol>
<hr />
<h3 id="13-training-objective">1.3 Training Objective<a class="headerlink" href="#13-training-objective" title="Permanent link">&para;</a></h3>
<p>The training objective for the diffusion model is to maximize the variational lower bound (ELBO) on the log-likelihood expressed as:</p>
<div class="arithmatex">\[
\text{ELBO}_{\phi, \theta}(x) = \mathbb{E}_{q_\phi(x_{1:T}|x_0)} [\log p_\theta(x_0|x_1)] 
- \text{D}_{\text{KL}}(q_\phi(x_T|x_0) || p(x_T)) 
- \sum_{t=2}^T \mathbb{E}_{q_\phi(x_t|x_0)} \left[ \text{D}_{\text{KL}} \left( q_\phi(x_{t-1}|x_t, x_0) || p_\theta(x_{t-1}|x_t) \right) \right]
\]</div>
<p>The first component of the equation, the reconstruction term, measures how well the model <span class="arithmatex">\(p_\theta\)</span> can reconstruct the initial data point <span class="arithmatex">\(x_0\)</span> from the latent variable <span class="arithmatex">\(x_1\)</span>, using the log-likelihood <span class="arithmatex">\(p_\theta(x_0|x_1)\)</span>. The second component involves the KL divergence, which measures the difference between the distribution <span class="arithmatex">\(q_\phi(x_T|x_0)\)</span> and the prior distribution <span class="arithmatex">\(p(x_T)\)</span>. The last component, the consistency term, sums the KL divergences across transitions for <span class="arithmatex">\(t = 2\)</span> to <span class="arithmatex">\(T\)</span>, measuring the alignment between the forward transition modeled by <span class="arithmatex">\(q_\phi(x_{t-1}|x_t, x_0)\)</span> and the reverse transition <span class="arithmatex">\(p_\theta(x_{t-1}|x_t)\)</span>. The ELBO can be further simplified to get a loss function (see <sup id="fnref3:15"><a class="footnote-ref" href="#fn:15">15</a></sup>):</p>
<div class="arithmatex">\[
\theta^* = \underset{\theta}{\text{arg min}} \sum_{t=1}^T \frac{1}{2\sigma^2(t)} 
\frac{(1-\alpha_t)^2 \alpha_{t-1}}{(1-\alpha_t)^2} \mathbb{E}_{q(x_t|x_0)} \left[ \| \hat{x}_\theta(x_t) - x_0 \|^2 \right].
\]</div>
<p>Algorithm 1 and 2 summarize the training and inference procedures for the diffusion model.</p>
<h3 id="14-guided-diffusion">1.4 Guided Diffusion<a class="headerlink" href="#14-guided-diffusion" title="Permanent link">&para;</a></h3>
<p>In many applications, like text prompt-based image generation, generating samples from a conditional distribution <span class="arithmatex">\( p(x|c) \)</span> is desired where <span class="arithmatex">\( c \)</span> is the conditioning variable. But the diffusion model can assign insufficient weight on these conditions, so additional pressure called "guidance" is applied, resulting in guided diffusion <sup id="fnref3:11"><a class="footnote-ref" href="#fn:11">11</a></sup>. </p>
<p>There are primarily two types of guidance: <strong>classifier guidance</strong> and <strong>classifier-free guidance</strong>.
1. <strong>Classifier Guidance</strong>: In this approach, a separate classifier model <span class="arithmatex">\(p(c|x)\)</span>is utilized along with a diffusion model to drive the sample generation towards desired characteristics defined by the conditional label <span class="arithmatex">\(c\)</span> <sup id="fnref:16"><a class="footnote-ref" href="#fn:16">16</a></sup>.
2. <strong>Classifier-Free Guidance</strong>: In this approach, rather than employing a separate classifier for guidance, conditional and unconditional diffusion processes are jointly trained to achieve the desired outcomes <sup id="fnref:17"><a class="footnote-ref" href="#fn:17">17</a></sup>.</p>
<hr />
<h2 id="2-graph-diffusion-models">2. Graph Diffusion Models<a class="headerlink" href="#2-graph-diffusion-models" title="Permanent link">&para;</a></h2>
<p>A graph <span class="arithmatex">\(G\)</span>, defined as a pair <span class="arithmatex">\(G = (V, E)\)</span>, is a fundamental structure in mathematics and computer science used to model relationships and interaction between the objects. Here <span class="arithmatex">\(V\)</span> is a set of vertices and <span class="arithmatex">\(E\)</span> is a set of edges, each connecting a pair of vertices. Graphs can be used to model different complex and interconnected data like social networks, recommendation systems, biological networks, and other areas, which makes adaptation of generative models like diffusion models for graphs quite crucial.</p>
<p>As illustrated in Fig 2, DDPM on graphs involves forward and reverse processes where the primary focus is on creating a transition kernel for the Markov chain <sup id="fnref:18"><a class="footnote-ref" href="#fn:18">18</a></sup>. Various methods have been proposed to achieve that. Haefeli et al. <sup id="fnref:19"><a class="footnote-ref" href="#fn:19">19</a></sup> proposed using discrete noise for the forward Markov process instead of using continuous Gaussian perturbations, which ensured that for every intermediate step, the graph remained discrete, resulting in better and faster sample generation. We discuss the forward and reverse process proposed by <sup id="fnref2:19"><a class="footnote-ref" href="#fn:19">19</a></sup> in Section 2.1 and 2.2.</p>
<h3 id="21-forward-process">2.1 Forward Process<a class="headerlink" href="#21-forward-process" title="Permanent link">&para;</a></h3>
<p>The diffusion model generates a sequence from an initial simple graph <span class="arithmatex">\(A_0\)</span> (adjacency matrix representing the graph) to white noise <span class="arithmatex">\(A_T\)</span> through a series of increasingly noisier graphs <span class="arithmatex">\(A_1, A_2, \ldots, A_T\)</span>. Both <span class="arithmatex">\(A_0\)</span> and <span class="arithmatex">\(A_T\)</span> are adjacency matrices where <span class="arithmatex">\(A_0\)</span> is a sample from the dataset and <span class="arithmatex">\(A_T\)</span> is an Erdős–Rényi <sup id="fnref:20"><a class="footnote-ref" href="#fn:20">20</a></sup> random graph.</p>
<p>Each element <span class="arithmatex">\(a_{ij}^t\)</span> of the adjacency matrix between nodes <span class="arithmatex">\(i\)</span> and <span class="arithmatex">\(j\)</span> is encoded as a one-hot vector and transformed by a double stochastic matrix <span class="arithmatex">\(Q_t\)</span> defined as:</p>
<div class="arithmatex">\[
Q_t = 
\begin{bmatrix}
1 - \beta_t &amp; \beta_t \\
\beta_t &amp; 1 - \beta_t
\end{bmatrix}
\]</div>
<p>Here, <span class="arithmatex">\(\beta_t\)</span> indicates the probability of the edge state not changing. This formulation allows for direct sampling at any timestep <span class="arithmatex">\(t\)</span> independently for each edge and non-edge, facilitating the simplification of the sampling process without relying on previous timesteps.</p>
<h3 id="22-reverse-process">2.2 Reverse Process<a class="headerlink" href="#22-reverse-process" title="Permanent link">&para;</a></h3>
<p>Reverse process aims to recover the original graph from the noise. The reverse transition is denoted as <span class="arithmatex">\(q(A_{t-1}|A_t, A_0)\)</span> and is crucial for training to learn to denoise the graphs. The reverse transition probabilities are derived from the forward probabilities with a dependence on the initial graph <span class="arithmatex">\( A_0 \)</span> to ensure accurate regeneration of the graph given as:</p>
<div class="arithmatex">\[
q(A_{t-1}|A_t, A_0) = \frac{q(A_t | A_{t-1}) q(A_{t-1} | A_0)}{q(A_t | A_0)}.
\]</div>
<h3 id="23-latent-diffusion">2.3 Latent Diffusion<a class="headerlink" href="#23-latent-diffusion" title="Permanent link">&para;</a></h3>
<p>Diffusion over discrete graph space can suffer from different issues, primarily high modeling complexity, complex relational information leading to limited semantic learning, and consequently poor performance <sup id="fnref:21"><a class="footnote-ref" href="#fn:21">21</a></sup>. Instead, using a latent space can improve efficiency with faster sampling and produce better samples by producing smoother representation <sup id="fnref2:21"><a class="footnote-ref" href="#fn:21">21</a></sup> <sup id="fnref:22"><a class="footnote-ref" href="#fn:22">22</a></sup> <sup id="fnref:23"><a class="footnote-ref" href="#fn:23">23</a></sup>. </p>
<p>This is generally achieved by first training a variational graph autoencoder (VGAE) to capture topological information and then applying diffusion with some conditioning on its latent space to enhance the representation, and finally using the decoder to generate the graph <sup id="fnref3:21"><a class="footnote-ref" href="#fn:21">21</a></sup> <sup id="fnref2:22"><a class="footnote-ref" href="#fn:22">22</a></sup> <sup id="fnref2:23"><a class="footnote-ref" href="#fn:23">23</a></sup>  <sup id="fnref:24"><a class="footnote-ref" href="#fn:24">24</a></sup>.</p>
<hr />
<h2 id="3-applications">3 Applications<a class="headerlink" href="#3-applications" title="Permanent link">&para;</a></h2>
<p>Graph diffusion models have demonstrated substantial efficacy across a diverse range of fields like biology, chemistry, physics, computer science, and others. In this section, we will explore several applications of these models, highlighting their role and impact in research and industry.</p>
<h3 id="31-molecule-and-protein-design">3.1 Molecule and Protein Design<a class="headerlink" href="#31-molecule-and-protein-design" title="Permanent link">&para;</a></h3>
<p>Diffusion models can generate novel molecules by learning the distribution of existing molecular graphs. This is particularly useful for discovering new drugs with desired properties. For example, <strong>DiffHopp</strong> <sup id="fnref:25"><a class="footnote-ref" href="#fn:25">25</a></sup> is a graph diffusion model tailored for scaffold hopping in drug design, which modifies the core structure of known active compounds to generate new chemical entities while preserving essential molecular features. Similarly, they are powerful tools for predicting protein structures and interactions, which is vital to understanding biological processes and designing new therapeutics. For example, models such as <strong>DiffDock</strong> <sup id="fnref:26"><a class="footnote-ref" href="#fn:26">26</a></sup> facilitate molecular coupling by predicting how small molecules bind to proteins.</p>
<h3 id="32-materials-design">3.2 Materials Design<a class="headerlink" href="#32-materials-design" title="Permanent link">&para;</a></h3>
<p>Graph diffusion models are used to design new materials with specific properties by generating graphs that represent the structures of the material, which can then be analyzed for their physical and chemical properties. By learning the graph structures of existing materials, these models can propose new materials with enhanced characteristics, such as increased strength or conductivity, which makes the methods quite relevant in fields like nanotechnology and materials science <sup id="fnref:27"><a class="footnote-ref" href="#fn:27">27</a></sup>.</p>
<h3 id="33-combinatorial-optimization">3.3 Combinatorial Optimization<a class="headerlink" href="#33-combinatorial-optimization" title="Permanent link">&para;</a></h3>
<p>Graph diffusion models are also applied in solving combinatorial optimization problems, where the goal is to find the best solution from a finite set of possible solutions. Models like <strong>DIFUSCO</strong> <sup id="fnref:28"><a class="footnote-ref" href="#fn:28">28</a></sup> can generate candidate solutions for problems like the traveling salesman and maximal independent set problem.</p>
<h3 id="34-xai">3.4 xAI<a class="headerlink" href="#34-xai" title="Permanent link">&para;</a></h3>
<p>Machine learning models are generally "black box" in nature, making them untrustworthy and unreliable. Explainable AI (xAI) refers to methods and systems that make such models explainable and interpretable. Graph Neural Networks (GNNs) are also black-box in nature, and diffusion models like <strong>D4Explainer</strong> <sup id="fnref:29"><a class="footnote-ref" href="#fn:29">29</a></sup> can produce both counterfactual and model-level explanations for GNNs.</p>
<hr />
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image generation with clip latents, 2022.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. High-resolution image synthesis with latent diffusion models, 2021.&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>Video generation models as world simulators — OpenAI.&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p>Thomas Macaulay. OpenAI’s new image generator sparks both excitement and fear, April 2022.&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:5">
<p>Kevin Roose. AI-generated art is already transforming creative work. <em>The New York Times</em>, October 2022.&#160;<a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:6">
<p>OpenAI reveals Sora, a tool to make instant videos from written prompts, February 2024.&#160;<a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
<li id="fn:7">
<p>Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. <em>(arXiv:1503.03585)</em>, November 2015. [arXiv:1503.03585 [cond-mat, q-bio, stat]].&#160;<a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text">&#8617;</a></p>
</li>
<li id="fn:8">
<p>Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In <em>Advances in Neural Information Processing Systems</em>, volume 33, page 6840–6851. Curran Associates, Inc., 2020.&#160;<a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 8 in the text">&#8617;</a></p>
</li>
<li id="fn:9">
<p>Fick’s laws of diffusion, July 2024. Page Version ID: 1235588853.&#160;<a class="footnote-backref" href="#fnref:9" title="Jump back to footnote 9 in the text">&#8617;</a></p>
</li>
<li id="fn:10">
<p>Diffusion models.&#160;<a class="footnote-backref" href="#fnref:10" title="Jump back to footnote 10 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:10" title="Jump back to footnote 10 in the text">&#8617;</a></p>
</li>
<li id="fn:11">
<p>Christopher M. Bishop and Hugh Bishop. <em>Deep Learning: Foundations and Concepts</em>. Springer International Publishing, Cham, 2024.&#160;<a class="footnote-backref" href="#fnref:11" title="Jump back to footnote 11 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:11" title="Jump back to footnote 11 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:11" title="Jump back to footnote 11 in the text">&#8617;</a></p>
</li>
<li id="fn:12">
<p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks, 2014.&#160;<a class="footnote-backref" href="#fnref:12" title="Jump back to footnote 12 in the text">&#8617;</a></p>
</li>
<li id="fn:13">
<p>Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin Cui, and Ming-Hsuan Yang. Diffusion models: A comprehensive survey of methods and applications. <em>(arXiv:2209.00796)</em>, June 2024. [arXiv:2209.00796 [cs]].&#160;<a class="footnote-backref" href="#fnref:13" title="Jump back to footnote 13 in the text">&#8617;</a></p>
</li>
<li id="fn:14">
<p>Image generation with diffusion models using Keras and TensorFlow — by Vedant Jumle — Towards Data Science.&#160;<a class="footnote-backref" href="#fnref:14" title="Jump back to footnote 14 in the text">&#8617;</a></p>
</li>
<li id="fn:15">
<p>Stanley H. Chan. Tutorial on diffusion models for imaging and vision. <em>(arXiv:2403.18103)</em>, March 2024. [arXiv:2403.18103 [cs]].&#160;<a class="footnote-backref" href="#fnref:15" title="Jump back to footnote 15 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:15" title="Jump back to footnote 15 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:15" title="Jump back to footnote 15 in the text">&#8617;</a></p>
</li>
<li id="fn:16">
<p>Prafulla Dhariwal and Alex Nichol. Diffusion models beat GANs on image synthesis, 2021.&#160;<a class="footnote-backref" href="#fnref:16" title="Jump back to footnote 16 in the text">&#8617;</a></p>
</li>
<li id="fn:17">
<p>Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. In <em>NeurIPS 2021 Workshop on Deep Generative Models and Downstream Applications</em>, 2021.&#160;<a class="footnote-backref" href="#fnref:17" title="Jump back to footnote 17 in the text">&#8617;</a></p>
</li>
<li id="fn:18">
<p>Chengyi Liu, Wenqi Fan, Yunqing Liu, Jiatong Li, Hang Li, Hui Liu, Jiliang Tang, and Qing Li. Generative diffusion models on graphs: Methods and applications. <em>(arXiv:2302.02591)</em>, August 2023. [arXiv:2302.02591 [cs]].&#160;<a class="footnote-backref" href="#fnref:18" title="Jump back to footnote 18 in the text">&#8617;</a></p>
</li>
<li id="fn:19">
<p>Kilian Konstantin Haefeli, Karolis Martinkus, Nathanaël Perraudin, and Roger Wattenhofer. Diffusion models for graphs benefit from discrete state spaces, 2023.&#160;<a class="footnote-backref" href="#fnref:19" title="Jump back to footnote 19 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:19" title="Jump back to footnote 19 in the text">&#8617;</a></p>
</li>
<li id="fn:20">
<p>Paul Erdős and Alfréd Rényi. On the evolution of random graphs. <em>Publ. Math. Inst. Hungar. Acad. Sci.</em>, 5:17–61, 1960.&#160;<a class="footnote-backref" href="#fnref:20" title="Jump back to footnote 20 in the text">&#8617;</a></p>
</li>
<li id="fn:21">
<p>Ling Yang, Zhilin Huang, Zhilong Zhang, Zhongyi Liu, Shenda Hong, Wentao Zhang, Wenming Yang, Bin Cui, and Luxia Zhang. Graphusion: Latent diffusion for graph generation. <em>IEEE Transactions on Knowledge and Data Engineering</em>, page 1–12, 2024.&#160;<a class="footnote-backref" href="#fnref:21" title="Jump back to footnote 21 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:21" title="Jump back to footnote 21 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:21" title="Jump back to footnote 21 in the text">&#8617;</a></p>
</li>
<li id="fn:22">
<p>Iakovos Evdaimon, Giannis Nikolentzos, Michail Chatzianastasis, Hadi Abdine, and Michalis Vazirgiannis. Neural graph generator: Feature-conditioned graph generation using latent diffusion models. <em>arXiv preprint arXiv:2403.01555</em>, 2024.&#160;<a class="footnote-backref" href="#fnref:22" title="Jump back to footnote 22 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:22" title="Jump back to footnote 22 in the text">&#8617;</a></p>
</li>
<li id="fn:23">
<p>Minkai Xu, Alexander S Powers, Ron O Dror, Stefano Ermon, and Jure Leskovec. Geometric latent diffusion models for 3d molecule generation. In <em>International Conference on Machine Learning</em>, pages 38592–38610. PMLR, 2023.&#160;<a class="footnote-backref" href="#fnref:23" title="Jump back to footnote 23 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:23" title="Jump back to footnote 23 in the text">&#8617;</a></p>
</li>
<li id="fn:24">
<p>Cong Fu, Keqiang Yan, Limei Wang, Tao Komikado, Koji Maruhashi, Kanji Uchino, Xiaoning Qian, and Shuiwang Ji. A latent diffusion model for protein structure generation.&#160;<a class="footnote-backref" href="#fnref:24" title="Jump back to footnote 24 in the text">&#8617;</a></p>
</li>
<li id="fn:25">
<p>Jos Torge, Charles Harris, Simon V. Mathis, and Pietro Lio. Diffhopp: A graph diffusion model for novel drug design via scaffold hopping, 2023.&#160;<a class="footnote-backref" href="#fnref:25" title="Jump back to footnote 25 in the text">&#8617;</a></p>
</li>
<li id="fn:26">
<p>Gabriele Corso, Hannes Stärk, Bowen Jing, Regina Barzilay, and Tommi Jaakkola. Diffdock: Diffusion steps, twists, and turns for molecular docking, 2023.&#160;<a class="footnote-backref" href="#fnref:26" title="Jump back to footnote 26 in the text">&#8617;</a></p>
</li>
<li id="fn:27">
<p>Mengchun Zhang, Maryam Qamar, Taegoo Kang, Yuna Jung, Chenshuang Zhang, Sung-Ho Bae, and Chaoning Zhang. A survey on graph diffusion models: Generative AI in science for molecule, protein and material. <em>arXiv preprint arXiv:2304.01565</em>, 2023.&#160;<a class="footnote-backref" href="#fnref:27" title="Jump back to footnote 27 in the text">&#8617;</a></p>
</li>
<li id="fn:28">
<p>Zhiqing Sun and Yiming Yang. Diffusco: Graph-based diffusion solvers for combinatorial optimization. <em>Advances in Neural Information Processing Systems</em>, 36:3706–3731, 2023.&#160;<a class="footnote-backref" href="#fnref:28" title="Jump back to footnote 28 in the text">&#8617;</a></p>
</li>
<li id="fn:29">
<p>Jialin Chen, Shirley Wu, Abhijit Gupta, and Rex Ying. D4explainer: In-distribution explanations of graph neural network via discrete denoising diffusion. <em>Advances in Neural Information Processing Systems</em>, 36, 2024.&#160;<a class="footnote-backref" href="#fnref:29" title="Jump back to footnote 29 in the text">&#8617;</a></p>
</li>
</ol>
</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.footnote.tooltips"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
      
    
  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>